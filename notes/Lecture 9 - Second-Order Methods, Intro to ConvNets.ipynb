{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First vs Second Order methods\n",
    "- SGD, Adam, RMSProp, etc are all first order methods that have the leanringr ate as a yperparameter\n",
    "- First order: only uses first derivative (the gradient)\n",
    "    - Basically does a linear approximation via the gradient at $\\theta_t$\n",
    "- Second-order: us curvature of the cost function to know how to take steps\n",
    "- curvature: smaller steps if the curvature is steep, otherwise we can take larger steps\n",
    "- take a quadratic approximation of $J$ at $\\theta_t$, \n",
    "\n",
    "#### Newton's method\n",
    "- Consider talyor series expansion of $J(\\theta)$ around $\\theta_0$ up to teh second oerder term. \n",
    "- Doesn't require a learning rate.\n",
    "- Compute graident $g \\in R^n$, compute hessian $H \\in R^n{*n}$\n",
    "- Update is $\\theta = \\theta - H^{-1}g$. \n",
    "- Main downsides:\n",
    "    - Memory to store the Hessian. 1 * 10^6 parameters -> Hessian will be 3.6 TB to store!\n",
    "    - Inverting the Hessian takes $O(n^3)$\n",
    "    - Hessians typicall reuqire a very large batch size\n",
    "- Quasi-Newton: BFGS, limited-memory BFGS\n",
    "- Exploding/vanishing gradients issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Neural Networks\n",
    "- Started revival of neural nets in 2012\n",
    "- 1998: LeNet\n",
    "- Biological inspiration of CNNs:\n",
    "    - Simple cells: Spatially localized affine transformations, followed by thresholding -> relu\n",
    "    - complex cells: pooling units, incprportate invariance to slight shifts in the postion of the feature\n",
    "- Limitations in analogy: \n",
    "    - CNNs have no feedback connections, no recurrent connections\n",
    "- CNNs also have a lot less paramters, since the first few layers are not FC layers. i.e. if you have a $ 200 * 200 $ pixel image, each neuron in the first layer only would require $200 * 200 * 3$ parameters!\n",
    "- Takes longer to train and more prone to overfitting\n",
    "\n",
    "#### Convolutions\n",
    "- Conv operation typically done in 3d, defines a collection of filters/activation maps with teh same dimension as the input\n",
    "- Output of conv layer is just a concat of all of the features together\n",
    "- pointwise relu\n",
    "\n",
    "#### conv layers have sparse interactions\n",
    "- Each output is connected to only a small number of inputs\n",
    "- i.e. each activation is only looking at a small spatial extent of the iamge\n",
    "- reduces computation time\n",
    "- An issue with only having a single layer is that inputs from different regions don't interact, so this is the motivation for having multiple conv layers\n",
    "\n",
    "\n",
    "#### Number of neurons\n",
    "- FC: Number of connections to a single neuron in CIFAR-10: $(32 * 32 * 3)$, and there are 500 neurons in the first layer, so there are $(32 * 32 * 3 +1)(500) = 1.5$ million parameters in the first layer of an FC network\n",
    "\n",
    "#### Outputs of conv layers\n",
    "- If you zero pad (i.e. add zeros so that the filter can occupy a corener) then the output will have dimensions $W + F - 1$ (input size + filter size - 1). \n",
    "- Usually, if we don't zero pad, the conv operation is $N-F + 1$\n",
    "- If you pad, the output is $N - F + 1 + 2pad$\n",
    "- Value of padding: between pad = 0 and pad that causes the output and input to have the same dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
